{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SireDestiny/Deep-Learning/blob/main/Tomi_deep_learning_challenge_solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMfMoAq6qS6b"
      },
      "source": [
        "#import warnings\n",
        "#warnings.filterwarnings(\"ignore\")\n",
        "import seaborn as sns\n",
        "import os, cv2, random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "#%pylab inline\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from matplotlib import ticker\n",
        "import seaborn as sns\n",
        "#%matplotlib inline \n",
        "\n",
        "#from tensorflow import keras \n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Dropout, Flatten, Convolution2D, MaxPooling2D, Dense, Activation\n",
        "#from keras.optimizers import RMSprop\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "import cv2\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y00-int3ra3P"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "# Add convolutional and pooling layers\n",
        "\n",
        "# The pictures are 100 x 100 pixels, with rgb (3) --> (100,100,3)\n",
        "model.add(layers.Input((100, 100, 3)))\n",
        "\n",
        "# Layer with 16 filters, 3 x 3, activation = relu\n",
        "model.add(layers.Conv2D(16, (3, 3), activation='relu'))\n",
        "# Pooling\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# Layer with 16 filters, 3 x 3, activation = relu again\n",
        "model.add(layers.Conv2D(16, (3, 3), activation='relu'))\n",
        "\n",
        "# Pooling again\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# Flatten layer \n",
        "model.add(layers.Flatten())\n",
        "\n",
        "# Add a Dense layer with 64 units and relu activation\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "\n",
        "# Add the last Dense layer with sigmoid activation\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydwfaYzjryUq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab54b0f1-203a-4d37-d74d-442331e08b49"
      },
      "source": [
        "model.summary()\n",
        "# Model summary appears the same as baseline model from assignment description"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_2 (Conv2D)            (None, 98, 98, 16)        448       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 49, 49, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 47, 47, 16)        2320      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 23, 23, 16)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 8464)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                541760    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 544,593\n",
            "Trainable params: 544,593\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMMVf92_m7z9"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"dl2909-project.ipynb\n",
        "\n",
        "Automatically generated by Colaboratory.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "#for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        " #   for filename in filenames:\n",
        "    \n",
        "  #      print(os.path.join(dirname, filename))\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
        "\n",
        "## 31020201\n",
        "\n",
        "### NEW\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## 03102021\n",
        "\n",
        "### NEW2\n",
        "\n",
        "\n",
        "## 03102021\n",
        "\n",
        "## 03102021\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                shear_range = 0.2,\n",
        "                zoom_range = 0.2,\n",
        "                width_shift_range = 0.2,\n",
        "                height_shift_range = 0.2,\n",
        "                fill_mode=\"nearest\",\n",
        "                validation_split=0.15)\n",
        "\n",
        "## 03102021\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "## 03102021\n",
        "\n",
        "\n",
        "train_data = train_datagen.flow_from_directory(\"../input/deep-l/Train/Train\",\n",
        "                                      target_size=(100,100),\n",
        "                                       seed=123,\n",
        "                                       batch_size=32,\n",
        "                                       subset=\"training\"\n",
        "                                      )\n",
        "\n",
        "val_data = train_datagen.flow_from_directory(\"../input/deep-l/Test/Test\",\n",
        "                                      target_size=(100,100),\n",
        "                                       seed=123,\n",
        "                                       batch_size=32,\n",
        "                                       subset=\"validation\"\n",
        "                                      )\n",
        "test_data = test_datagen.flow_from_directory(\"../input/deep-l/archive (2)/faces\",\n",
        "                                    target_size=(100,100),\n",
        "                                    seed=123,\n",
        "                                    batch_size=32,\n",
        "                                    shuffle=False)\n",
        "\n",
        "## 03102021\n",
        "\n",
        "\n",
        "vggModel = VGG16(weights=\"imagenet\", input_shape=(100,100,3), include_top=False)\n",
        "\n",
        "## 03102021\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# Add convolutional and pooling layers\n",
        "\n",
        "# The pictures are 100 x 100 pixels, with rgb (3) --> (100,100,3)\n",
        "model.add(layers.Input((100, 100, 3)))\n",
        "\n",
        "# Layer with 16 filters, 3 x 3, activation = relu\n",
        "model.add(layers.Conv2D(16, (3, 3), activation='relu'))\n",
        "# Pooling\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# Layer with 16 filters, 3 x 3, activation = relu again\n",
        "model.add(layers.Conv2D(16, (3, 3), activation='relu'))\n",
        "\n",
        "# Pooling again\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# Flatten layer \n",
        "model.add(layers.Flatten())\n",
        "\n",
        "# Add a Dense layer with 64 units and relu activation\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "\n",
        "# Add the last Dense layer with sigmoid activation\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "## 03102021\n",
        "\n",
        "for layer in vggModel.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "## 03102021\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras import Sequential\n",
        "\n",
        "model = Sequential()\n",
        "model.add(vggModel)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=2, activation=\"sigmoid\"))\n",
        "\n",
        "## 03102021\n",
        "\n",
        "#import keras\n",
        "model.compile(optimizer=keras.optimizers.Adam(lr=0.01), loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
        "\n",
        "## 03102021\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "## 03102021\n",
        "\n",
        "callbacks = [EarlyStopping(monitor=\"val_accuracy\",patience=3),\n",
        "            ModelCheckpoint(\"Model.1\",verbose= 1 ,save_best_only=True)]\n",
        "\n",
        "## 03102021\n",
        "\n",
        "hist = model.fit_generator(generator=train_data, \n",
        "                          steps_per_epoch=len(train_data)//128,\n",
        "                          epochs=5, validation_data=val_data,\n",
        "                          validation_steps=len(val_data)//128,\n",
        "                          callbacks=callbacks)\n",
        "\n",
        "plt.figure(figsize=(15,6))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(hist.epoch,hist.history['accuracy'],label = 'Training')\n",
        "#plt.plot(hist.epoch,hist.history['val_accuracy'],label = 'validation')\n",
        "\n",
        "plt.title(\"Accuracy\")\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(hist.epoch,hist.history['loss'],label = 'Training')\n",
        "#plt.plot(hist.epoch,hist.history['val_loss'],label = 'validation')\n",
        "\n",
        "plt.title(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORSGoP6T4Bx_"
      },
      "source": [
        "plt.figure(figsize=(15,6))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(hist.epoch,hist.history['accuracy'],label = 'Training')\n",
        "plt.plot(hist.epoch,hist.history['val_accuracy'],label = 'validation')\n",
        "\n",
        "plt.title(\"Accuracy\")\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(hist.epoch,hist.history['loss'],label = 'Training')\n",
        "plt.plot(hist.epoch,hist.history['val_loss'],label = 'validation')\n",
        "\n",
        "plt.title(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "## For evaluating the accuracy and loss-function\n",
        "\n",
        "model_END = keras.models.load_model(\"./Model\")\n",
        "pred = model_END.predict(test_data, verbose=1)\n",
        "\n",
        "\n",
        "## Import packages for the evaluation exercise. \n",
        "\n",
        "predicted = [np.argmax(i) for i in pred]\n",
        "confidence = [np.round((max(i)*100),2) for i in pred]\n",
        "\n",
        "y_test = test_data.classes\n",
        "\n",
        "classification_report(predicted,y_test)\n",
        "\n",
        "print(classification_report(predicted,y_test))\n",
        "\n",
        "sns.heatmap(confusion_matrix(predicted,y_test),annot=True,fmt=\"d\",cmap=\"Blues\");\n",
        "\n",
        "## Now, let's try it out\n",
        "\n",
        "\n",
        "\n",
        "## For the processing of the images \n",
        "\n",
        "img = cv2.imread(\"../input/{inset image here}.jpg\")\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}